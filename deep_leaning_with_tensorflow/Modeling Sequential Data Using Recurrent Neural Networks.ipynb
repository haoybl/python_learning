{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from string import punctuation\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_path = 'C:/Users/LENOVO/Desktop/movie_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_data = pd.read_csv(reviews_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nothing is fantastic! Simple as that! It's a f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This really was a waste of time...the movie ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This might sound weird, but I only got to see ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Considering this film was released 8 years bef...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Very rarely does one come across an indie come...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  Nothing is fantastic! Simple as that! It's a f...          1\n",
       "1  This really was a waste of time...the movie ha...          0\n",
       "2  This might sound weird, but I only got to see ...          0\n",
       "3  Considering this film was released 8 years bef...          1\n",
       "4  Very rarely does one come across an indie come...          1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I Sell the Dead is a big, sloppy horror comedy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>I know this sounds odd coming from someone bor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>OK I had higher hopes for this Carnosaur movie...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Laurence Fishburne is a fine actor, and deserv...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>I lived in Tokyo for 7 months. Knowing the rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "49995  I Sell the Dead is a big, sloppy horror comedy...          1\n",
       "49996  I know this sounds odd coming from someone bor...          1\n",
       "49997  OK I had higher hopes for this Carnosaur movie...          0\n",
       "49998  Laurence Fishburne is a fine actor, and deserv...          1\n",
       "49999  I lived in Tokyo for 7 months. Knowing the rea...          1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique words\n",
    "counter = Counter()\n",
    "\n",
    "# clean text\n",
    "for i, review in enumerate(movie_data['review']):\n",
    "    \n",
    "    text = \"\".join(c if c not in punctuation else \" {} \".format(c) for c in review).lower()\n",
    "    movie_data.iloc[i, 0] = text\n",
    "    \n",
    "    counter.update(text.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2int dictionary\n",
    "word2int = {w:i for i, w in enumerate(sorted(counter, key=counter.get, reverse=True), start=1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# int-list reviews\n",
    "mapped_reviews = []\n",
    "for review in movie_data['review']:\n",
    "    mapped_reviews.append([word2int[word] for word in review.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 200\n",
    "\n",
    "# if length < sequence_length : left padd with zeros\n",
    "# if length > sequence_length : take last 'sequence_length' elements\n",
    "\n",
    "# padded sequence\n",
    "sequences = np.zeros(shape=(len(movie_data), sequence_length), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, mapped_review in enumerate(mapped_reviews):\n",
    "    n = len(mapped_review)\n",
    "    if n < sequence_length:\n",
    "        sequences[i, -n:] = mapped_review\n",
    "    else:\n",
    "        sequences[i, :] = mapped_review[-sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25000, 200), (25000,), (25000, 200), (25000,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = sequences[:25000, :]\n",
    "y_train = movie_data.iloc[:25000, 1].values\n",
    "\n",
    "X_test = sequences[25000:, :]\n",
    "y_test = movie_data.iloc[25000:, 1].values\n",
    "\n",
    "X_train.shape, y_train.shape, X_test.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12500, 200), (12500,), (12500, 200), (12500,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val = X_test[:12500]\n",
    "y_val = y_test[:12500]\n",
    "X_test = X_test[12500:]\n",
    "y_test = y_test[12500:]\n",
    "\n",
    "X_val.shape, y_val.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(X, y=None, batch_size=64):\n",
    "    if y is not None:\n",
    "        assert len(X) == len(y)\n",
    "    n_batch = len(X) // batch_size\n",
    "    for i in range(n_batch):\n",
    "        a = i*batch_size\n",
    "        b = (i+1)*batch_size\n",
    "        \n",
    "        if y is not None:\n",
    "            yield X[a:b], y[a:b]\n",
    "        else:\n",
    "            yield X[a:b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentRNN:\n",
    "    \n",
    "    def __init__(self, word_size, embed_size=200, lstm_size=256, num_layer=1,\n",
    "                seq_length=200, learning_rate=1e-4, batch_size=32):\n",
    "        # model hyper parameters\n",
    "        self.word_size = word_size\n",
    "        self.embed_size = embed_size\n",
    "        self.lstm_size = lstm_size\n",
    "        self.num_layer = num_layer\n",
    "        self.seq_length = seq_length\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        # build model graph\n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            #tf.set_random_seed(123)\n",
    "            self.build()\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    def build(self):\n",
    "        # placeholder for inputs\n",
    "        tf_x = tf.placeholder(dtype=tf.int32, \n",
    "                              shape=(self.batch_size, self.seq_length), \n",
    "                              name='tf_x')\n",
    "        tf_y = tf.placeholder(dtype=tf.float32, \n",
    "                              shape=(self.batch_size), \n",
    "                              name='tf_y')\n",
    "        tf_keepprob = tf.placeholder(dtype=tf.float32, shape=(), \n",
    "                                     name='tf_keepprob')\n",
    "        # embedding vector\n",
    "        W_embedding = tf.Variable(\n",
    "            tf.random_uniform(shape=(self.word_size, self.embed_size), minval=-1, maxval=1),\n",
    "            name='W_embedding')\n",
    "        \n",
    "        embed_x = tf.nn.embedding_lookup(W_embedding, tf_x, name='embed_x')\n",
    "        \n",
    "        # create rnn cell\n",
    "        cells = tf.contrib.rnn.MultiRNNCell([\n",
    "            tf.contrib.rnn.DropoutWrapper(tf.contrib.rnn.BasicLSTMCell(self.lstm_size),\n",
    "                                         output_keep_prob=tf_keepprob)\n",
    "                                          for i in range(self.num_layer)\n",
    "        ])\n",
    "        \n",
    "        # define the initial state/ rnn steps\n",
    "        self.initial_state = cells.zero_state(self.batch_size, tf.float32)\n",
    "        print(\"  << initial state > \", self.initial_state)\n",
    "        \n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(cell=cells, inputs=embed_x, \n",
    "                                                           initial_state=self.initial_state)\n",
    "        print(\"\\n << lstm_output >> \", lstm_outputs)\n",
    "        print(\"\\n << final state >> \", self.final_state)\n",
    "        \n",
    "        # dense layer -> logits\n",
    "        logits = tf.layers.dense(inputs=lstm_outputs[:, -1], units=1, \n",
    "                                 activation=None, name='logits')\n",
    "        \n",
    "        logits = tf.squeeze(logits, name='logits_squeezed')\n",
    "        print('\\n  << logits     >> ', logits)\n",
    "        \n",
    "        # predictions -> prob. | labels\n",
    "        y_proba = tf.nn.sigmoid(logits, name='probabilities')\n",
    "        y_labels = tf.cast(tf.round(logits), dtype=tf.int32, name='labels')\n",
    "        predictions = {\n",
    "            'probabilities': y_proba,\n",
    "            'labels': y_labels\n",
    "        }\n",
    "        print(\"\\n << predictions  >> \", predictions)\n",
    "        \n",
    "        # cost function\n",
    "        cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=tf_y, \n",
    "                                                                      logits=logits), \n",
    "                              name='cost')\n",
    "        # optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train_op = optimizer.minimize(cost, name='train_op')\n",
    "    \n",
    "    def train(self, X, y, num_epochs):\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            sess.run(self.init_op)\n",
    "            \n",
    "            batch_total = 0\n",
    "            for epoch in range(num_epochs):\n",
    "                # reset cell&hidden states\n",
    "                state = sess.run(self.initial_state)\n",
    "                for x_batch, y_batch in batch_generator(X, y, batch_size=self.batch_size):\n",
    "                    feed = {'tf_x:0': x_batch,\n",
    "                            'tf_y:0': y_batch,\n",
    "                            'tf_keepprob:0': 0.5,\n",
    "                            self.initial_state: state}\n",
    "                    loss, _, state = sess.run(['cost:0', 'train_op', self.final_state], \n",
    "                                              feed_dict=feed)\n",
    "                    \n",
    "                    # update training every 20 batches\n",
    "                    batch_total += 1\n",
    "                    if (batch_total+1) % 20 == 0:\n",
    "                        print(\"Epoch {:3d}, Iterations {:4d}, Training loss: {:.4f}\".format(epoch+1, \n",
    "                                                                                            batch_total+1,\n",
    "                                                                                            loss))\n",
    "                # save every 10 epochs                                                                          \n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    self.saver.save(sess, \n",
    "                                    'model/sentiment-rnn-{}.ckpt'.format(epoch+1))\n",
    "    \n",
    "    def predict(self, X, predict_proba=False):\n",
    "        pred = []\n",
    "        with tf.Session(graph=self.g) as sess:\n",
    "            # restore latest model\n",
    "            self.saver.restore(sess, \n",
    "                               tf.train.latest_checkpoint('./model/'))\n",
    "            \n",
    "            # init model states\n",
    "            state = sess.run(self.initial_state)\n",
    "            \n",
    "            for x_batch in batch_generator(X, y=None, batch_size=self.batch_size):\n",
    "                feed = {'tf_x:0': x_batch,\n",
    "                        'tf_keepprob:0': 1.0,\n",
    "                        self.initial_state: state}\n",
    "                \n",
    "                if predict_proba:\n",
    "                    y_pred, state = sess.run(['probabilities:0', self.final_state], \n",
    "                                           feed_dict=feed)\n",
    "                else:\n",
    "                    y_pred, state = sess.run(['labels:0', self.final_state], \n",
    "                                            feed_dict=feed)\n",
    "                pred.append(y_pred)\n",
    "                \n",
    "        return np.concatenate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  << initial state >  (LSTMStateTuple(c=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros:0' shape=(32, 256) dtype=float32>, h=<tf.Tensor 'MultiRNNCellZeroState/DropoutWrapperZeroState/BasicLSTMCellZeroState/zeros_1:0' shape=(32, 256) dtype=float32>),)\n",
      "\n",
      " << lstm_output >>  Tensor(\"rnn/transpose_1:0\", shape=(32, 200, 256), dtype=float32)\n",
      "\n",
      " << final state >>  (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_3:0' shape=(32, 256) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_4:0' shape=(32, 256) dtype=float32>),)\n",
      "\n",
      "  << logits     >>  Tensor(\"logits_squeezed:0\", shape=(32,), dtype=float32)\n",
      "\n",
      " << predictions  >>  {'labels': <tf.Tensor 'labels:0' shape=(32,) dtype=int32>, 'probabilities': <tf.Tensor 'probabilities:0' shape=(32,) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "model = SentimentRNN(word_size=max(word2int.values())+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dl_no_gpu]",
   "language": "python",
   "name": "conda-env-dl_no_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
