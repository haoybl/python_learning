{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from html import unescape\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "CONTRACTION_MAP = pickle.load(open('contraction_map.pkl', 'rb'))\n",
    "\n",
    "wnl = nltk.wordnet.WordNetLemmatizer()\n",
    "\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "\n",
    "def parse_document(doc):\n",
    "    doc = re.sub('\\n', ' ', doc).strip()    \n",
    "    return [sent.strip() for sent in nltk.sent_tokenize(doc)]\n",
    "\n",
    "def unescape_html(text):\n",
    "    return unescape(text)\n",
    "\n",
    "def expand_contractions(text, contraction_map):\n",
    "    \n",
    "    pat = re.compile(\"({})\".format(\"|\".join(contraction_map.keys())), \n",
    "                     flags=re.IGNORECASE|re.DOTALL)\n",
    "    \n",
    "    def expand_match(match_object):\n",
    "        text = match_object.group(0)\n",
    "        new_text = contraction_map.get(text, contraction_map.get(text.lower()))\n",
    "        return text[0] + new_text[1:]\n",
    "        \n",
    "    return pat.sub(expand_match, text)\n",
    "\n",
    "\n",
    "def remove_special_characters(text):\n",
    "    pat = re.compile(\"[{}]\".format(re.escape(string.punctuation)))\n",
    "    return pat.sub(\"\", text)\n",
    "\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    return \" \".join(w for w in nltk.word_tokenize(text) if w not in stop_words)\n",
    "\n",
    "\n",
    "def tokenize_text(text):\n",
    "    return [w.strip() for w in nltk.word_tokenize(text)]\n",
    "\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    \n",
    "    def penn_to_wn(tag):\n",
    "        if tag.startswith('JJ'):\n",
    "            return wn.ADJ\n",
    "        elif tag.startswith('NN'):\n",
    "            return wn.NOUN\n",
    "        elif tag.startswith('RB'):\n",
    "            return wn.ADV\n",
    "        elif tag.startswith('VB'):\n",
    "            return wn.VERB\n",
    "        return None\n",
    "\n",
    "    text_tagged = ((word.lower(), penn_to_wn(tag)) for word, tag in nltk.pos_tag(tokenize_text(text)))\n",
    "    return \" \".join(wnl.lemmatize(word, pos=tag) if tag else word for word, tag in text_tagged)\n",
    "\n",
    "\n",
    "def normalize_corpus(corpus, lemmatize=True, tokenize=False):\n",
    "    \n",
    "    normalized_corpus = []\n",
    "    for text in corpus:\n",
    "        \n",
    "        text = unescape_html(text)\n",
    "        text = expand_contractions(text, CONTRACTION_MAP)\n",
    "        \n",
    "        if lemmatize:\n",
    "            text = lemmatize_text(text)\n",
    "        else:\n",
    "            text = text.lower()\n",
    "        \n",
    "        text = remove_special_characters(text)\n",
    "        text = remove_stopwords(text)\n",
    "        \n",
    "        if tokenize:\n",
    "            normalized_corpus.append(tokenize_text(text))\n",
    "        else:\n",
    "            normalized_corpus.append(text)\n",
    "        \n",
    "    return normalized_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "\n",
    "def build_feature_matrix(corpus, feature_type='freq'):\n",
    "    \n",
    "    if feature_type == 'freq':\n",
    "        vectorizer = CountVectorizer(binary=False, min_df=1, ngram_range=(1, 1))\n",
    "    \n",
    "    elif feature_type == 'binary':\n",
    "        vectorizer = CountVectorizer(binary=True, min_df=1, ngram_range=(1, 1))\n",
    "    \n",
    "    elif feature_type == 'tfidf':\n",
    "        vectorizer = TfidfVectorizer(min_df=1, ngram_range=(1, 1))\n",
    "    \n",
    "    else:\n",
    "        raise Exception('Invalid feature type:\\n\\\n",
    "                        Possible values: {}, {}, {}'.format(\"`freq`\", \"`binary`\", \"`tfidf`\"))\n",
    "    \n",
    "    features = vectorizer.fit_transform(corpus).astype(float)\n",
    "    \n",
    "    return vectorizer, features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten_corpus(corpus):\n",
    "    return \" \".join(text.strip() for text in corpus)\n",
    "\n",
    "def compute_ngrams(sequence, n_gram):\n",
    "    return list(zip(*(sequence[i:] for i in range(n_gram))))\n",
    "\n",
    "\n",
    "def get_top_ngrams(corpus, ngram_val=1, limit=5):\n",
    "    \n",
    "    corpus = flatten_corpus(corpus)\n",
    "    tokens = nltk.word_tokenize(corpus)\n",
    "    \n",
    "    ngrams = compute_ngrams(tokens, n_gram=ngram_val)\n",
    "    ngrams_freq = nltk.FreqDist(samples=ngrams)\n",
    "    sorted_ngrams = sorted(ngrams_freq.items(), \n",
    "                           key=lambda x: x[1], \n",
    "                           reverse=True)\n",
    "    return [(\" \".join(ngram), freq) for ngram, freq in  sorted_ngrams[:limit]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice = gutenberg.sents(fileids='carroll-alice.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alice = [\" \".join(s) for s in alice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_alice = list(filter(None, normalize_corpus(alice, lemmatize=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[ Alice ' s Adventures in Wonderland by Lewis Carroll 1865 ]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alice adventures wonderland lewis carroll 1865'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_alice[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, 3), (2, 3, 4)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_ngrams([1,2,3,4], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said alice', 123),\n",
       " ('mock turtle', 56),\n",
       " ('march hare', 31),\n",
       " ('said king', 29),\n",
       " ('thought alice', 26),\n",
       " ('said hatter', 22),\n",
       " ('white rabbit', 22),\n",
       " ('said mock', 20),\n",
       " ('said gryphon', 18),\n",
       " ('said caterpillar', 18)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(norm_alice, ngram_val=2, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said mock turtle', 20),\n",
       " ('said march hare', 10),\n",
       " ('poor little thing', 6),\n",
       " ('certainly said alice', 5),\n",
       " ('little golden key', 5),\n",
       " ('march hare said', 5),\n",
       " ('white kid gloves', 5),\n",
       " ('mock turtle said', 5),\n",
       " ('mouse mouse mouse', 4),\n",
       " ('ootiful soo oop', 4)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_ngrams(norm_alice, ngram_val=3, limit=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### nltk - collocation finders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bigrams\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.collocations import BigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bi_finder = BigramCollocationFinder.from_documents(list(map(nltk.word_tokenize, norm_alice)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigram_measures = BigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'alice'),\n",
       " ('mock', 'turtle'),\n",
       " ('march', 'hare'),\n",
       " ('said', 'king'),\n",
       " ('thought', 'alice'),\n",
       " ('said', 'hatter'),\n",
       " ('white', 'rabbit'),\n",
       " ('said', 'mock'),\n",
       " ('said', 'caterpillar'),\n",
       " ('said', 'gryphon')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_finder.nbest(bigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('abide', 'figures'),\n",
       " ('acceptance', 'elegant'),\n",
       " ('accounting', 'tastes'),\n",
       " ('accustomed', 'usurpation'),\n",
       " ('act', 'crawling'),\n",
       " ('adjourn', 'immediate'),\n",
       " ('adoption', 'energetic'),\n",
       " ('affair', 'trusts'),\n",
       " ('agony', 'terror'),\n",
       " ('alarmed', 'proposal')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_finder.nbest(bigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trigrams\n",
    "from nltk.collocations import TrigramCollocationFinder, TrigramAssocMeasures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tri_finder = TrigramCollocationFinder.from_documents(list(map(nltk.word_tokenize, norm_alice)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_measures = TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 'mock', 'turtle'),\n",
       " ('said', 'march', 'hare'),\n",
       " ('poor', 'little', 'thing'),\n",
       " ('little', 'golden', 'key'),\n",
       " ('march', 'hare', 'said'),\n",
       " ('mock', 'turtle', 'said'),\n",
       " ('white', 'kid', 'gloves'),\n",
       " ('beau', 'ootiful', 'soo'),\n",
       " ('certainly', 'said', 'alice'),\n",
       " ('might', 'well', 'say')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_finder.nbest(trigram_measures.raw_freq, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('accustomed', 'usurpation', 'conquest'),\n",
       " ('adjourn', 'immediate', 'adoption'),\n",
       " ('adoption', 'energetic', 'remedies'),\n",
       " ('ancient', 'modern', 'seaography'),\n",
       " ('apple', 'roast', 'turkey'),\n",
       " ('arithmetic', 'ambition', 'distraction'),\n",
       " ('brother', 'latin', 'grammar'),\n",
       " ('canvas', 'bag', 'tied'),\n",
       " ('cherry', 'tart', 'custard'),\n",
       " ('circle', 'exact', 'shape')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_finder.nbest(trigram_measures.pmi, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weighted Tag-Based Phrase Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import nltk\n",
    "from gensim import corpora, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toy_text = \"\"\"\n",
    "Elephants are large mammals of the family Elephantidae \n",
    "and the order Proboscidea. Two species are traditionally recognised, \n",
    "the African elephant and the Asian elephant. Elephants are scattered \n",
    "throughout sub-Saharan Africa, South Asia, and Southeast Asia. Male \n",
    "African elephants are the largest extant terrestrial animals. All \n",
    "elephants have a long trunk used for many purposes, \n",
    "particularly breathing, lifting water and grasping objects. Their \n",
    "incisors grow into tusks, which can serve as weapons and as tools \n",
    "for moving objects and digging. Elephants' large ear flaps help \n",
    "to control their body temperature. Their pillar-like legs can \n",
    "carry their great weight. African elephants have larger ears \n",
    "and concave backs while Asian elephants have smaller ears \n",
    "and convex or level backs.  \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "noun_grammar = r'NP: {<DT>? <JJ>* <NN.*>+}'\n",
    "sentences = parse_document(toy_text)\n",
    "\n",
    "def get_chunks(sentences, grammar=noun_grammar):\n",
    "\n",
    "    # build chunker based on grammar pattern\n",
    "    all_chunks = []\n",
    "    chunker = nltk.chunk.regexp.RegexpParser(grammar)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # POS tag sentences\n",
    "        tagged_sents = nltk.pos_tag_sents([nltk.word_tokenize(sentence)])\n",
    "\n",
    "        # extract chunks: tree\n",
    "        chunks = [chunker.parse(tagged_sent) for tagged_sent in tagged_sents]\n",
    "\n",
    "        # get word, pos_tag, chunk_tag triples\n",
    "        wtc_sents = [nltk.chunk.tree2conlltags(chunk) for chunk in chunks]\n",
    "\n",
    "        flattened_chunks = list(itertools.chain.from_iterable(wtc for wtc in wtc_sents))\n",
    "\n",
    "        # get valid chunks based on tags\n",
    "        valid_chunks_tagged = [(status, list(chunk)) \n",
    "                               for status, chunk in itertools.groupby(flattened_chunks, lambda x: x[-1]!='O') if status]\n",
    "\n",
    "        # append words in each chunk to make phrases\n",
    "        valid_chunks = [\" \".join(w.lower() for w,_,_ in chunks if w.lower() not in stop_words) \n",
    "                        for _, chunks in valid_chunks_tagged]\n",
    "\n",
    "        all_chunks.append(valid_chunks)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "\n",
    "def get_tfidf_weighted_keyphrases(sentences, grammar=r\"NP: <DT>? <JJ>* <NN.*>+\", top_n=10):\n",
    "    \n",
    "    valid_chunks = get_chunks(sentences, grammar)\n",
    "    \n",
    "    # build tf-idf based model\n",
    "    chunk_dict = corpora.Dictionary(valid_chunks)\n",
    "    corpus = [chunk_dict.doc2bow(chunk) for chunk in valid_chunks]\n",
    "    tfidf = models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tfidf[corpus]\n",
    "    \n",
    "    # get phrases and their tf-idf weights\n",
    "    weighted_phrases = {chunk_dict.get(idx): round(val, 3) \n",
    "                            for doc in corpus_tfidf \n",
    "                            for (idx, val) in doc}\n",
    "    weighted_phrases = sorted(weighted_phrases.items(), key=lambda x: x[1], reverse=True)\n",
    "    return weighted_phrases[:top_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['elephants', 'large mammals', 'family elephantidae', 'order proboscidea'],\n",
       " ['species', 'african elephant', 'asian elephant'],\n",
       " ['elephants', 'sub-saharan africa', 'south asia', 'southeast asia'],\n",
       " ['male african elephants', 'extant terrestrial animals'],\n",
       " ['elephants',\n",
       "  'long trunk',\n",
       "  'many purposes',\n",
       "  'breathing',\n",
       "  'water',\n",
       "  'grasping objects'],\n",
       " ['incisors', 'tusks', 'weapons', 'tools', 'objects', 'digging'],\n",
       " ['elephants', 'large ear flaps', 'body temperature'],\n",
       " ['pillar-like legs', 'great weight'],\n",
       " ['african elephants',\n",
       "  'ears',\n",
       "  'backs',\n",
       "  'asian elephants',\n",
       "  'ears',\n",
       "  'convex',\n",
       "  'level backs']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_chunks(parse_document(toy_text), noun_grammar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('male african elephants', 0.707),\n",
       " ('great weight', 0.707),\n",
       " ('pillar-like legs', 0.707),\n",
       " ('extant terrestrial animals', 0.707),\n",
       " ('body temperature', 0.684),\n",
       " ('large ear flaps', 0.684),\n",
       " ('ears', 0.667),\n",
       " ('species', 0.577),\n",
       " ('african elephant', 0.577),\n",
       " ('asian elephant', 0.577)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_weighted_keyphrases(sentences, noun_grammar, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('particular bill', 1.0),\n",
       " ('prisoner', 1.0),\n",
       " ('manage twelfth', 1.0),\n",
       " ('blacking believe', 1.0),\n",
       " ('chapter ii', 1.0),\n",
       " ('end bill french music', 1.0),\n",
       " ('tails mouths crumbs', 1.0),\n",
       " ('continued way', 1.0),\n",
       " ('mock turtle sing song', 1.0),\n",
       " ('experiment', 1.0),\n",
       " ('play croquet queen day', 1.0),\n",
       " ('thump', 1.0),\n",
       " ('book', 1.0),\n",
       " ('deny', 1.0),\n",
       " ('next question world', 1.0),\n",
       " ('inquired alice', 1.0),\n",
       " ('oh poor hands', 1.0),\n",
       " ('stay', 1.0),\n",
       " ('right think', 1.0),\n",
       " ('melancholy tone', 1.0)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tfidf_weighted_keyphrases(norm_alice, noun_grammar, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2 distinct topics corpus: [animal, programming language]\n",
    "\n",
    "toy_corpus = [\"The fox jumps over the dog\",\n",
    "\"The fox is very clever and quick\",\n",
    "\"The dog is slow and lazy\",\n",
    "\"The cat is smarter than the fox and the dog\",\n",
    "\"Python is an excellent programming language\",\n",
    "\"Java and Ruby are other programming languages\",\n",
    "\"Python and Java are very popular programming languages\",\n",
    "\"Python programs are smaller than Java programs\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Latent Semantic Indexing (LSI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['fox', 'jump', 'dog'],\n",
       " ['fox', 'clever', 'quick'],\n",
       " ['dog', 'slow', 'lazy'],\n",
       " ['cat', 'smarter', 'fox', 'dog'],\n",
       " ['python', 'excellent', 'programming', 'language'],\n",
       " ['java', 'ruby', 'programming', 'language'],\n",
       " ['python', 'java', 'popular', 'programming', 'language'],\n",
       " ['python', 'program', 'small', 'java', 'program']]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_tokenized_corpus = normalize_corpus(toy_corpus, tokenize=True)\n",
    "norm_tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# build Bag-of-word model\n",
    "bow = corpora.Dictionary(norm_tokenized_corpus)\n",
    "\n",
    "bow_corpus = [bow.doc2bow(doc) for doc in norm_tokenized_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 1), (1, 1), (2, 1)],\n",
       " [(1, 1), (3, 1), (4, 1)],\n",
       " [(0, 1), (5, 1), (6, 1)],\n",
       " [(0, 1), (1, 1), (7, 1), (8, 1)],\n",
       " [(9, 1), (10, 1), (11, 1), (12, 1)],\n",
       " [(9, 1), (11, 1), (13, 1), (14, 1)],\n",
       " [(9, 1), (10, 1), (11, 1), (14, 1), (15, 1)],\n",
       " [(10, 1), (14, 1), (16, 2), (17, 1)]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tfidf model\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "\n",
    "tfidf_corpus = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fix the number of topic\n",
    "n_topic = 2\n",
    "\n",
    "lsi = models.LsiModel(corpus=tfidf_corpus, num_topics=n_topic, id2word=bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "0.459*\"language\" + 0.459*\"programming\" + 0.344*\"python\" + 0.344*\"java\" + 0.336*\"popular\" + 0.318*\"excellent\" + 0.318*\"ruby\" + 0.148*\"program\" + 0.074*\"small\" + 0.000*\"dog\"\n",
      "\n",
      "Topic 1:\n",
      "-0.459*\"dog\" + -0.459*\"fox\" + -0.444*\"jump\" + -0.322*\"cat\" + -0.322*\"smarter\" + -0.208*\"lazy\" + -0.208*\"slow\" + -0.208*\"clever\" + -0.208*\"quick\" + 0.000*\"language\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lsi.print_topics(n_topic):\n",
    "    print(\"Topic {}:\\n{}\\n\".format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_topic_gensim(topic_model, total_topic=1, weight_threshold=0.0001, \n",
    "                       display_weights=False, num_terms=None):\n",
    "    for i in range(total_topic):\n",
    "        topic = topic_model.show_topic(i)\n",
    "        \n",
    "        topic = [(word, round(val, 2)) for  word, val in topic \n",
    "                                         if abs(val) > weight_threshold]\n",
    "        \n",
    "        print(\"Topic {}:\".format(i))\n",
    "        if not display_weights:\n",
    "            print([w for w,_ in topic][:num_terms])\n",
    "        else:\n",
    "            print(topic[:num_terms])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('language', 0.46000000000000002), ('programming', 0.46000000000000002), ('python', 0.34000000000000002), ('java', 0.34000000000000002), ('popular', 0.34000000000000002)]\n",
      "\n",
      "Topic 1:\n",
      "[('dog', -0.46000000000000002), ('fox', -0.46000000000000002), ('jump', -0.44), ('cat', -0.32000000000000001), ('smarter', -0.32000000000000001)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_gensim(lsi, total_topic=2, num_terms=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSI using SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def low_rank_svd(matrix, singular_count=2):\n",
    "    u, s, vt = svds(matrix, k=singular_count)\n",
    "    return u, s, vt\n",
    "\n",
    "def build_tfidf_matrix(corpus):\n",
    "    tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 1))\n",
    "    features = tfidf.fit_transform(corpus)\n",
    "    return tfidf, features\n",
    "\n",
    "def get_topics_with_terms_and_weights(weights, feature_names):\n",
    "    topics = []\n",
    "    for weight in weights:\n",
    "        a = pd.Series(weight, index=feature_names)\n",
    "        idx = a.abs().argsort().values[::-1]\n",
    "        topics.append(a.iloc[idx].round(3))\n",
    "    return topics\n",
    "\n",
    "\n",
    "def train_lsi_model_gensim(corpus, n_topics=2):\n",
    "    \n",
    "    corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    bow = corpora.Dictionary(corpus)\n",
    "    bow_corpus = [bow.doc2bow(doc) for doc in corpus]\n",
    "    tfidf = models.TfidfModel(bow_corpus)\n",
    "    tfidf_corpus = tfidf[bow_corpus]\n",
    "    \n",
    "    lsi = models.LsiModel(corpus=tfidf_corpus, \n",
    "                          num_topics=n_topics, \n",
    "                          id2word=bow)\n",
    "    return lsi\n",
    "\n",
    "def print_topics(weights, feature_names, weight_threshold=0.0001, num_terms=None):\n",
    "    \n",
    "    topics = get_topics_with_terms_and_weights(weights, feature_names)\n",
    "    for i, topic in enumerate(topics, 1):\n",
    "        topic = topic.loc[topic.abs() >= weight_threshold]\n",
    "        print(\"Topic {}:\\n{}\".format(i, topic[:num_terms]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 18)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "\n",
    "# tfidf_matrix -> [n_docs, n_words]\n",
    "vectorizer, tfidf_matrix = build_tfidf_matrix(norm_corpus)\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# td_matrix -> [n_words, n_docs]\n",
    "td_matrix = tfidf_matrix.T\n",
    "td_matrix = td_matrix.multiply(td_matrix > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_topic = 2\n",
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u, s, vt = low_rank_svd(td_matrix, singular_count=n_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weights = (u * s).T    # shape -> [n_topic, n_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = get_topics_with_terms_and_weights(weights, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog            0.724\n",
      "fox            0.724\n",
      "jump           0.430\n",
      "smarter        0.336\n",
      "cat            0.336\n",
      "slow           0.234\n",
      "lazy           0.234\n",
      "quick          0.234\n",
      "clever         0.234\n",
      "programming    0.000\n",
      "language       0.000\n",
      "java           0.000\n",
      "python         0.000\n",
      "popular        0.000\n",
      "program        0.000\n",
      "ruby           0.000\n",
      "excellent      0.000\n",
      "small          0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(topics[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "programming   -0.729\n",
      "language      -0.729\n",
      "python        -0.565\n",
      "java          -0.565\n",
      "popular       -0.341\n",
      "ruby          -0.333\n",
      "excellent     -0.333\n",
      "program       -0.213\n",
      "small         -0.106\n",
      "dog            0.000\n",
      "fox            0.000\n",
      "lazy           0.000\n",
      "slow           0.000\n",
      "jump           0.000\n",
      "smarter        0.000\n",
      "cat            0.000\n",
      "quick          0.000\n",
      "clever         0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(topics[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog        0.724\n",
       "fox        0.724\n",
       "jump       0.430\n",
       "smarter    0.336\n",
       "cat        0.336\n",
       "slow       0.234\n",
       "lazy       0.234\n",
       "quick      0.234\n",
       "clever     0.234\n",
       "dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[0][(topics[0].abs() > .15).values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_lda_model_gensim(corpus, total_topics=2):\n",
    "    \n",
    "    norm_tokenized_corpus = normalize_corpus(corpus, tokenize=True)\n",
    "    id2word = corpora.Dictionary(norm_tokenized_corpus)\n",
    "    mapped_corpus = [id2word.doc2bow(doc) for doc in norm_tokenized_corpus]\n",
    "    tfidf = models.TfidfModel(mapped_corpus)\n",
    "    tfidf_corpus = tfidf[mapped_corpus]\n",
    "    lda = models.LdaModel(tfidf_corpus, \n",
    "                          num_topics=total_topics, \n",
    "                          id2word=id2word, \n",
    "                          iterations=1000)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_gensim = train_lda_model_gensim(toy_corpus, total_topics=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('language', 0.070000000000000007), ('jump', 0.070000000000000007), ('fox', 0.070000000000000007), ('dog', 0.059999999999999998), ('programming', 0.059999999999999998), ('excellent', 0.059999999999999998), ('quick', 0.059999999999999998), ('clever', 0.059999999999999998), ('lazy', 0.059999999999999998), ('python', 0.059999999999999998)]\n",
      "\n",
      "Topic 1:\n",
      "[('java', 0.070000000000000007), ('popular', 0.070000000000000007), ('programming', 0.059999999999999998), ('program', 0.059999999999999998), ('ruby', 0.059999999999999998), ('language', 0.059999999999999998), ('python', 0.059999999999999998), ('smarter', 0.059999999999999998), ('dog', 0.059999999999999998), ('fox', 0.059999999999999998)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_gensim(lda_gensim, total_topic=2, display_weights=True, num_terms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_tfidf_matrix(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50,\n",
       "             max_doc_update_iter=100, max_iter=100, mean_change_tol=0.001,\n",
       "             n_components=2, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=42, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_topics = 2\n",
    "lda = LatentDirichletAllocation(n_components=total_topics, \n",
    "                                max_iter=100, \n",
    "                                learning_method='online', \n",
    "                                learning_offset=50, \n",
    "                                random_state=42)\n",
    "\n",
    "lda.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 18), 18)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = lda.components_\n",
    "\n",
    "weights.shape, len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "fox        1.846\n",
      "dog        1.538\n",
      "jump       1.173\n",
      "clever     1.113\n",
      "quick      1.113\n",
      "cat        1.057\n",
      "smarter    1.055\n",
      "dtype: float64\n",
      "\n",
      "Topic 2:\n",
      "programming    1.732\n",
      "language       1.727\n",
      "java           1.615\n",
      "python         1.583\n",
      "program        1.286\n",
      "ruby           1.090\n",
      "slow           1.078\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topics(weights, feature_names, num_terms=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "norm_corpus = normalize_corpus(toy_corpus)\n",
    "vectorizer, tfidf_matrix = build_tfidf_matrix(norm_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topic = 2\n",
    "nmf = NMF(n_components=n_topic, init='random', random_state=42, alpha=.1, l1_ratio=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta_loss='frobenius', init='random', l1_ratio=0.5,\n",
       "  max_iter=200, n_components=2, random_state=42, shuffle=False,\n",
       "  solver='cd', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "programming    0.551\n",
      "language       0.551\n",
      "python         0.402\n",
      "java           0.402\n",
      "popular        0.241\n",
      "excellent      0.235\n",
      "ruby           0.235\n",
      "program        0.090\n",
      "small          0.029\n",
      "dtype: float64\n",
      "\n",
      "Topic 2:\n",
      "dog        0.573\n",
      "fox        0.573\n",
      "jump       0.346\n",
      "smarter    0.255\n",
      "cat        0.255\n",
      "slow       0.132\n",
      "lazy       0.132\n",
      "quick      0.132\n",
      "clever     0.132\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topics(weights, feature_names, num_terms=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Topics from Product Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon_skyrim_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After playing this game over 100 hours in less...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a great ARPG, the improvements on the mechanic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A little buggy but such an amazing game it doe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazing game, cool graphics, cool gameplay, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bethesda adds here what it left out, or what w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0  After playing this game over 100 hours in less...\n",
       "1  a great ARPG, the improvements on the mechanic...\n",
       "2  A little buggy but such an amazing game it doe...\n",
       "3  Amazing game, cool graphics, cool gameplay, co...\n",
       "4  Bethesda adds here what it left out, or what w..."
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 1)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = data['Reviews'].values\n",
    "\n",
    "total_topics = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I base the value of a game on the amount of enjoyable gameplay I can get out of it and this one was definitely worth the price!\n"
     ]
    }
   ],
   "source": [
    "print(corpus[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Latent Semantic Indexing\n",
    "lsi_gensim = train_lsi_model_gensim(corpus, n_topics=total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['skyrim', 'like', 'one', 'play', 'quest', 'go', 'get', 'time', 'oblivion', 'good']\n",
      "\n",
      "Topic 1:\n",
      "['recommend', 'love', 'great', 'ever', 'best', 'buy', 'highly', 'elder', 'scroll', 'level']\n",
      "\n",
      "Topic 2:\n",
      "['recommend', 'fun', 'highly', 'love', 'ever', 'wonderful', 'best', 'series', 'definitely', 'scroll']\n",
      "\n",
      "Topic 3:\n",
      "['fun', 'recommend', 'scroll', 'elder', 'highly', 'ever', 'wonderful', 'graphic', 'best', 'cool']\n",
      "\n",
      "Topic 4:\n",
      "['fun', 'love', 'scroll', 'elder', 'highly', 'series', 'hour', 'recommend', 'always', 'ive']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_gensim(lsi_gensim, total_topic=total_topics, num_terms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA gensim\n",
    "lda_gensim = train_lda_model_gensim(corpus, total_topics=total_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "['skyrim', 'fun', 'one', 'great', 'like', 'play', 'go', 'buy', 'ever', 'glitch']\n",
      "\n",
      "Topic 1:\n",
      "['skyrim', 'quest', 'get', 'never', 'think', 'big', 'character', 'play', 'make', 'world']\n",
      "\n",
      "Topic 2:\n",
      "['play', 'love', 'get', 'quest', 'hour', 'oblivion', 'graphic', 'one', 'time', 'system']\n",
      "\n",
      "Topic 3:\n",
      "['recommend', 'love', 'like', 'fun', 'good', 'even', 'really', 'great', 'scroll', 'elder']\n",
      "\n",
      "Topic 4:\n",
      "['scroll', 'elder', 'oblivion', 'one', 'play', 'best', 'much', 'ever', 'love', 'go']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topic_gensim(lda_gensim, total_topic=total_topics, num_terms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='online', learning_offset=50,\n",
       "             max_doc_update_iter=100, max_iter=100, mean_change_tol=0.001,\n",
       "             n_components=5, n_jobs=1, n_topics=None, perp_tol=0.1,\n",
       "             random_state=None, topic_word_prior=None,\n",
       "             total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA sklearn\n",
    "norm_corpus = normalize_corpus(corpus)\n",
    "vectorizer, tfidf_matrix = build_tfidf_matrix(norm_corpus)\n",
    "\n",
    "lda_sk = LatentDirichletAllocation(n_components=total_topics, \n",
    "                                   learning_method='online', learning_offset=50, max_iter=100)\n",
    "\n",
    "lda_sk.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "de                 0.571\n",
      "crédito            0.398\n",
      "skyrimseguridad    0.398\n",
      "tarjeta            0.398\n",
      "compras            0.398\n",
      "recomiendo         0.398\n",
      "momento            0.398\n",
      "responsabilidad    0.398\n",
      "futuras            0.398\n",
      "para               0.398\n",
      "dtype: float64\n",
      "\n",
      "Topic 2:\n",
      "love          0.2\n",
      "fun           0.2\n",
      "booklet       0.2\n",
      "unrivaled     0.2\n",
      "definetley    0.2\n",
      "factory       0.2\n",
      "get           0.2\n",
      "staple        0.2\n",
      "whereas       0.2\n",
      "romp          0.2\n",
      "dtype: float64\n",
      "\n",
      "Topic 3:\n",
      "game       0.2\n",
      "play       0.2\n",
      "make       0.2\n",
      "skyrim     0.2\n",
      "great      0.2\n",
      "like       0.2\n",
      "hour       0.2\n",
      "one        0.2\n",
      "ever       0.2\n",
      "graphic    0.2\n",
      "dtype: float64\n",
      "\n",
      "Topic 4:\n",
      "game      38.348\n",
      "play      17.936\n",
      "get       13.440\n",
      "one       12.051\n",
      "skyrim    11.828\n",
      "great     11.377\n",
      "like      11.373\n",
      "time      11.040\n",
      "much      10.121\n",
      "go        10.116\n",
      "dtype: float64\n",
      "\n",
      "Topic 5:\n",
      "meadwaistlength            0.453\n",
      "peoplemudcrabsgreat        0.453\n",
      "musicdrinking              0.453\n",
      "nuff                       0.453\n",
      "wolfhoundsgiant            0.453\n",
      "helmetssnowy               0.453\n",
      "mountainsshouting          0.453\n",
      "beardsirish                0.453\n",
      "dragonsswordsaxespointy    0.453\n",
      "castle                     0.424\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = vectorizer.get_feature_names()\n",
    "weights = lda_sk.components_\n",
    "\n",
    "print_topics(weights, feature_names, num_terms=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NMF(alpha=0.1, beta_loss='frobenius', init='random', l1_ratio=0.5,\n",
       "  max_iter=200, n_components=5, random_state=42, shuffle=False,\n",
       "  solver='cd', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NNF\n",
    "nmf = NMF(n_components=total_topics, init='random', \n",
    "          random_state=42, alpha=.1, l1_ratio=.5)\n",
    "\n",
    "nmf.fit(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "game      0.756\n",
      "get       0.365\n",
      "skyrim    0.348\n",
      "play      0.326\n",
      "time      0.323\n",
      "like      0.318\n",
      "quest     0.303\n",
      "one       0.271\n",
      "go        0.267\n",
      "much      0.250\n",
      "dtype: float64\n",
      "\n",
      "Topic 2:\n",
      "game         0.685\n",
      "recommend    0.672\n",
      "love         0.653\n",
      "great        0.456\n",
      "highly       0.417\n",
      "play         0.276\n",
      "wonderful    0.265\n",
      "like         0.220\n",
      "would        0.153\n",
      "graphic      0.148\n",
      "dtype: float64\n",
      "\n",
      "Topic 3:\n",
      "scroll       0.731\n",
      "elder        0.721\n",
      "series       0.286\n",
      "always       0.280\n",
      "love         0.234\n",
      "pass         0.227\n",
      "buy          0.141\n",
      "far          0.140\n",
      "franchise    0.122\n",
      "every        0.121\n",
      "dtype: float64\n",
      "\n",
      "Topic 4:\n",
      "fun            1.335\n",
      "game           0.488\n",
      "much           0.194\n",
      "graphic        0.110\n",
      "improvement    0.094\n",
      "mission        0.079\n",
      "expect         0.069\n",
      "couple         0.063\n",
      "though         0.062\n",
      "favorite       0.058\n",
      "dtype: float64\n",
      "\n",
      "Topic 5:\n",
      "ever          0.759\n",
      "best          0.693\n",
      "game          0.605\n",
      "play          0.555\n",
      "one           0.240\n",
      "rpg           0.231\n",
      "great         0.222\n",
      "definitely    0.186\n",
      "hour          0.178\n",
      "ive           0.151\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_topics(nmf.components_, feature_names, num_terms=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automated Document Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nElephants are large mammals of the family Elephantidae \\nand the order Proboscidea. Two species are traditionally recognised, \\nthe African elephant and the Asian elephant. Elephants are scattered \\nthroughout sub-Saharan Africa, South Asia, and Southeast Asia. Male \\nAfrican elephants are the largest extant terrestrial animals. All \\nelephants have a long trunk used for many purposes, \\nparticularly breathing, lifting water and grasping objects. Their \\nincisors grow into tusks, which can serve as weapons and as tools \\nfor moving objects and digging. Elephants' large ear flaps help \\nto control their body temperature. Their pillar-like legs can \\ncarry their great weight. African elephants have larger ears \\nand concave backs while Asian elephants have smaller ears \\nand convex or level backs.  \\n\""
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize, keywords\n",
    "\n",
    "\n",
    "def text_summarization_gensim(text, summary_ratio=0.5):\n",
    "    '''summarize the given text to a fraction of its original size'''\n",
    "    summary = summarize(text, ratio=summary_ratio, split=True)\n",
    "    for sentence in summary:\n",
    "        print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \" \".join(parse_document(toy_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two species are traditionally recognised,  the African elephant and the Asian elephant.\n",
      "All  elephants have a long trunk used for many purposes,  particularly breathing, lifting water and grasping objects.\n",
      "African elephants have larger ears  and concave backs while Asian elephants have smaller ears  and convex or level backs.\n"
     ]
    }
   ],
   "source": [
    "text_summarization_gensim(text, summary_ratio=.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = parse_document(toy_text)\n",
    "norm_sentences = normalize_corpus(sentences, lemmatize=True, tokenize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(norm_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topic, n_sentence = 3, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bow = CountVectorizer(min_df=1, ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = np.array(parse_document(toy_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# term-sentence matrix\n",
    "bow_matrix = bow.fit_transform(sentences).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow_matrix = bow_matrix.multiply(bow_matrix > 0).asfptype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u, s, vt = low_rank_svd(bow_matrix, singular_count=n_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s[s < 0.5] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "salience_scores = np.sqrt(np.dot(np.square(s), np.square(vt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx = np.argsort(salience_scores)[::-1][:n_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'African elephants have larger ears  and concave backs while Asian elephants have smaller ears  and convex or level backs.',\n",
       "       'Their  incisors grow into tusks, which can serve as weapons and as tools  for moving objects and digging.',\n",
       "       'Two species are traditionally recognised,  the African elephant and the Asian elephant.'],\n",
       "      dtype='<U121')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lsa_text_summarizer(norm_sentences, num_sentences=3, \n",
    "                        num_topic=5, sv_threshold=0.5):\n",
    "    vec, dt_matrix = build_feature_matrix(norm_sentences)\n",
    "    td_matrix = dt_matrix.transpose()\n",
    "    td_matrix = td_matrix.multiply(td_matrix > 0)\n",
    "    \n",
    "    u, s, vt = low_rank_svd(td_matrix, singular_count=num_topic)\n",
    "    s[s < sv_threshold*max(s)] = 0\n",
    "    \n",
    "    ss = np.sqrt(np.dot(np.square(s), np.square(vt)))\n",
    "    idx = np.argsort(ss)[::-1][:num_sentences]\n",
    "    \n",
    "    for i in idx:\n",
    "        print(norm_sentences[i])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TextRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_sentences = 3\n",
    "\n",
    "vec, dt_matrix = build_tfidf_matrix(norm_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 59)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 9)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix = dt_matrix * dt_matrix.T\n",
    "similarity_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.  ,  0.07,  0.03,  0.12,  0.03,  0.  ,  0.11,  0.  ,  0.1 ],\n",
       "       [ 0.07,  1.  ,  0.06,  0.17,  0.05,  0.  ,  0.07,  0.  ,  0.24],\n",
       "       [ 0.03,  0.06,  1.  ,  0.03,  0.02,  0.  ,  0.03,  0.  ,  0.04],\n",
       "       [ 0.12,  0.17,  0.03,  1.  ,  0.03,  0.  ,  0.11,  0.  ,  0.17],\n",
       "       [ 0.03,  0.05,  0.02,  0.03,  1.  ,  0.07,  0.03,  0.  ,  0.04],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.07,  1.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.11,  0.07,  0.03,  0.11,  0.03,  0.  ,  1.  ,  0.  ,  0.25],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  1.  ,  0.  ],\n",
       "       [ 0.1 ,  0.24,  0.04,  0.17,  0.04,  0.  ,  0.25,  0.  ,  1.  ]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(similarity_matrix.todense(), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similarity_graph = networkx.from_scipy_sparse_matrix(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45236aec18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "networkx.draw_networkx(similarity_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = networkx.pagerank(similarity_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.12601516066915536), (1, 0.1176994845473083), (3, 0.11551107983088753)]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(scores.items(), key=lambda x: x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 'african elephant large ear concave back asian elephant small ear convex level back',\n",
       "       'two specie traditionally recognise african elephant asian elephant',\n",
       "       'male african elephant large extant terrestrial animal'],\n",
       "      dtype='<U86')"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(norm_sentences)[[8, 1, 3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def textrank_text_summarizer(documents, num_sentences=2):\n",
    "    \n",
    "    documents = parse_document(documents)\n",
    "    norm_doc = normalize_corpus(documents, lemmatize=True)\n",
    "    vec, tfidf_matrix = build_tfidf_matrix(norm_doc)\n",
    "    sim_matrix = tfidf_matrix * tfidf_matrix.T\n",
    "    \n",
    "    sim_graph = networkx.from_scipy_sparse_matrix(sim_matrix)\n",
    "    scores = networkx.pagerank(sim_graph)\n",
    "    \n",
    "    ranked_scores = sorted(scores.items(), key=lambda x:x[1], reverse=True)\n",
    "    \n",
    "    for i in range(num_sentences):\n",
    "        print(i, ':', documents[ranked_scores[i][0]])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : African elephants have larger ears  and concave backs while Asian elephants have smaller ears  and convex or level backs.\n",
      "\n",
      "1 : Two species are traditionally recognised,  the African elephant and the Asian elephant.\n",
      "\n",
      "2 : Male  African elephants are the largest extant terrestrial animals.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank_text_summarizer(toy_text, num_sentences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing a Product Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DOCUMENT = \"\"\"\n",
    "The Elder Scrolls V: Skyrim is an open world action role-playing video game \n",
    "developed by Bethesda Game Studios and published by Bethesda Softworks. \n",
    "It is the fifth installment in The Elder Scrolls series, following \n",
    "The Elder Scrolls IV: Oblivion. Skyrim's main story revolves around \n",
    "the player character and their effort to defeat Alduin the World-Eater, \n",
    "a dragon who is prophesied to destroy the world. \n",
    "The game is set two hundred years after the events of Oblivion \n",
    "and takes place in the fictional province of Skyrim. The player completes quests \n",
    "and develops the character by improving skills. \n",
    "Skyrim continues the open world tradition of its predecessors by allowing the \n",
    "player to travel anywhere in the game world at any time, and to \n",
    "ignore or postpone the main storyline indefinitely. The player may freely roam \n",
    "over the land of Skyrim, which is an open world environment consisting \n",
    "of wilderness expanses, dungeons, cities, towns, fortresses and villages. \n",
    "Players may navigate the game world more quickly by riding horses, \n",
    "or by utilizing a fast-travel system which allows them to warp to previously \n",
    "Players have the option to develop their character. At the beginning of the game, \n",
    "players create their character by selecting one of several races, \n",
    "including humans, orcs, elves and anthropomorphic cat or lizard-like creatures, \n",
    "and then customizing their character's appearance.discovered locations. Over the \n",
    "course of the game, players improve their character's skills, which are numerical \n",
    "representations of their ability in certain areas. There are eighteen skills \n",
    "divided evenly among the three schools of combat, magic, and stealth. \n",
    "Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's \n",
    "wilderness. Like other creatures, Dragons are generated randomly in the world \n",
    "and will engage in combat. \n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = parse_document(DOCUMENT)\n",
    "norm_sentences = normalize_corpus(sentences, lemmatize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Elder Scrolls V: Skyrim is an open world action role-playing video game  developed by Bethesda Game Studios and published by Bethesda Softworks.',\n",
       " 'It is the fifth installment in The Elder Scrolls series, following  The Elder Scrolls IV: Oblivion.',\n",
       " \"Skyrim's main story revolves around  the player character and their effort to defeat Alduin the World-Eater,  a dragon who is prophesied to destroy the world.\",\n",
       " 'The game is set two hundred years after the events of Oblivion  and takes place in the fictional province of Skyrim.',\n",
       " 'The player completes quests  and develops the character by improving skills.',\n",
       " 'Skyrim continues the open world tradition of its predecessors by allowing the  player to travel anywhere in the game world at any time, and to  ignore or postpone the main storyline indefinitely.',\n",
       " 'The player may freely roam  over the land of Skyrim, which is an open world environment consisting  of wilderness expanses, dungeons, cities, towns, fortresses and villages.',\n",
       " 'Players may navigate the game world more quickly by riding horses,  or by utilizing a fast-travel system which allows them to warp to previously  Players have the option to develop their character.',\n",
       " \"At the beginning of the game,  players create their character by selecting one of several races,  including humans, orcs, elves and anthropomorphic cat or lizard-like creatures,  and then customizing their character's appearance.discovered locations.\",\n",
       " \"Over the  course of the game, players improve their character's skills, which are numerical  representations of their ability in certain areas.\",\n",
       " 'There are eighteen skills  divided evenly among the three schools of combat, magic, and stealth.',\n",
       " \"Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's  wilderness.\",\n",
       " 'Like other creatures, Dragons are generated randomly in the world  and will engage in combat.']"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LSA document summarization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beginning game player create character select one several race include human orcs elf anthropomorphic cat lizardlike creature customize character appearancediscovered location\n",
      "\n",
      "player may navigate game world quickly rid horse utilize fasttravel system allow warp previously player option develop character\n",
      "\n",
      "skyrim continue open world tradition predecessor allow player travel anywhere game world time ignore postpone main storyline indefinitely\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lsa_text_summarizer(norm_sentences, num_sentences=3, num_topic=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : Skyrim is the first entry in The Elder Scrolls to include Dragons in the game's  wilderness.\n",
      "\n",
      "1 : The Elder Scrolls V: Skyrim is an open world action role-playing video game  developed by Bethesda Game Studios and published by Bethesda Softworks.\n",
      "\n",
      "2 : The player completes quests  and develops the character by improving skills.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "textrank_text_summarizer(DOCUMENT, num_sentences=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 5, 1])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(salience_scores)[::-1][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
